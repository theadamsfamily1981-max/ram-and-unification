# HBM_connectivity.cfg for Forest Kitten FK33 (VU35P + 8GB HBM2)
#
# Strategy: Non-contiguous PC allocation to maximize concurrent access
# and avoid AXI NoC crossbar saturation.
#
# PC layout:
#   PC[0-1]:   QKV weights (streaming read)
#   PC[4-5]:   FFN weights (streaming read)
#   PC[8-11]:  Attention temps (large streaming R/W)
#   PC[16-19]: Activation tiles (random access R/W)
#   PC[24]:    Output buffer (burst write)
#
# Rationale: Spreading across non-contiguous PCs ensures each bundle
# has dedicated HBM2 stack access with minimal crossbar contention.

[connectivity]

# ============================================================================
# GEMM Tile Top-Level Wrapper
# ============================================================================

# Activation tile bundle → PC[16-19]
# Random access working set, needs distributed access
sp=gemm_top_w4a8_1.m_axi_act_tiles:HBM[16]
sp=gemm_top_w4a8_1.m_axi_act_tiles:HBM[17]
sp=gemm_top_w4a8_1.m_axi_act_tiles:HBM[18]
sp=gemm_top_w4a8_1.m_axi_act_tiles:HBM[19]

# QKV weight bundle → PC[0-1]
# Spread across 2 PCs for 2× bandwidth (sequential streaming read)
sp=gemm_top_w4a8_1.m_axi_weights_qkv:HBM[0]
sp=gemm_top_w4a8_1.m_axi_weights_qkv:HBM[1]

# Output buffer → PC[24]
# Low bandwidth, single PC sufficient
sp=gemm_top_w4a8_1.m_axi_output_buf:HBM[24]

# ============================================================================
# Ara-SYNERGY SNN Encoder Kernel
# ============================================================================

# Model weights bundle (U/V/M low-rank factors) → PC[0-1]
# Spread across 2 PCs for 2× bandwidth (sequential streaming read)
# Read pattern: streaming access to low-rank factors during timestep loop
sp=ara_snn_encoder_kernel_1.m_axi_weights_qkv:HBM[0]
sp=ara_snn_encoder_kernel_1.m_axi_weights_qkv:HBM[1]

# Neuron state bundle (v, s for N=4096 neurons) → PC[16-19]
# Random access R/W for neuron states, distributed across 4 PCs
# Access pattern: read all states, update all states, every timestep
sp=ara_snn_encoder_kernel_1.m_axi_act_tiles:HBM[16]
sp=ara_snn_encoder_kernel_1.m_axi_act_tiles:HBM[17]
sp=ara_snn_encoder_kernel_1.m_axi_act_tiles:HBM[18]
sp=ara_snn_encoder_kernel_1.m_axi_act_tiles:HBM[19]

# Intermediate buffers bundle → PC[8-11]
# Large streaming R/W for temporary computations
# Used for intermediate SNN computations if needed
sp=ara_snn_encoder_kernel_1.m_axi_attn_temp:HBM[8]
sp=ara_snn_encoder_kernel_1.m_axi_attn_temp:HBM[9]
sp=ara_snn_encoder_kernel_1.m_axi_attn_temp:HBM[10]
sp=ara_snn_encoder_kernel_1.m_axi_attn_temp:HBM[11]

# Feature output buffer → PC[24]
# Low bandwidth, burst write for final acoustic features
sp=ara_snn_encoder_kernel_1.m_axi_output_buf:HBM[24]

# ============================================================================
# Bandwidth Summary
# ============================================================================
#
# Total HBM2 bandwidth: 32 PCs × ~8 GB/s = 256 GB/s theoretical
#
# Our allocation:
#   - QKV weights (PC[0-1]):   2 PCs × 8 GB/s = 16 GB/s available
#   - FFN weights (PC[4-5]):   2 PCs × 8 GB/s = 16 GB/s available
#   - Attention (PC[8-11]):    4 PCs × 8 GB/s = 32 GB/s available
#   - Activations (PC[16-19]): 4 PCs × 8 GB/s = 32 GB/s available
#   - Output (PC[24]):         1 PC  × 8 GB/s = 8 GB/s available
#
# Total allocated: 104 GB/s available (13 PCs out of 32)
# Expected sustained usage: ~20-30 GB/s
# Headroom: ~70 GB/s for bursts and optimization
